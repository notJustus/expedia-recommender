{
    "cells": [
     {
      "cell_type": "markdown",
      "id": "47c04715",
      "metadata": {},
      "source": [
       "# Feature Engineering - Expedia Hotel Recommendation\n",
       "\n",
       "This notebook focuses on creating and evaluating new features for the Expedia hotel recommendation dataset."
      ]
     },
     {
      "cell_type": "markdown",
      "id": "65c0c199",
      "metadata": {},
      "source": [
       "## 1. Setup and Data Loading"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e817a43",
      "metadata": {},
      "outputs": [],
      "source": [
       "import pandas as pd\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "import seaborn as sns\n",
       "from pathlib import Path\n",
       "import warnings\n",
       "warnings.filterwarnings('ignore')\n",
       "\n",
       "# Set style for better visualizations\n",
       "plt.style.use('seaborn-v0_8-whitegrid') # Using a more current style\n",
       "sns.set_palette('husl')\n",
       "\n",
       "# Set display options\n",
       "pd.set_option('display.max_columns', None)\n",
       "pd.set_option('display.max_rows', 100)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "5accc4eb",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Assuming your data loader is in the src directory relative to the workspace root\n",
       "import sys\n",
       "# IMPORTANT: Adjust this path if your 'src' directory is located elsewhere relative to 'notebooks'\n",
       "sys.path.append('../') # This makes the 'src' directory (and its submodules) available for import\n",
       "\n",
       "try:\n",
       "    from src.data.data_loader import load_data \n",
       "    print(\"Successfully imported load_data from src.data.data_loader\")\n",
       "except ImportError as e:\n",
       "    print(f\"Could not import load_data: {e}\")\n",
       "    print(f\"Current sys.path: {sys.path}\")\n",
       "    print(\"Please ensure 'src/data/data_loader.py' exists and the path is correct.\")\n",
       "    # Fallback or placeholder if data_loader is not found\n",
       "    def load_data(path, nrows=None):\n",
       "        print(f\"Fallback: Attempting to load data from: {path}\")\n",
       "        try:\n",
       "            return pd.read_csv(path, nrows=nrows)\n",
       "        except FileNotFoundError:\n",
       "            print(f\"Fallback Error: File not found at {path}\")\n",
       "            return pd.DataFrame()\n",
       "\n",
       "# Load the training data (adjust path as needed)\n",
       "# The path should be relative to the WORKSPACE ROOT, not the notebook file itself.\n",
       "TRAIN_DATA_PATH = '../data/train.csv' # Path from workspace root\n",
       "print(f\"Attempting to load data from: {TRAIN_DATA_PATH}\")\n",
       "train_df = load_data(TRAIN_DATA_PATH, nrows=None) # Load the full dataset or a large sample\n",
       "\n",
       "if not train_df.empty:\n",
       "    print(f\"Training data shape: {train_df.shape}\")\n",
       "    display(train_df.head())\n",
       "else:\n",
       "    print(\"Training data failed to load. Please check the path and data_loader configuration.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "338ed34e",
      "metadata": {},
      "source": [
       "## 2. Investigate `srch_destination_id` vs `prop_country_id`"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d98988e",
      "metadata": {},
      "outputs": [],
      "source": [
       "if 'train_df' in locals() and not train_df.empty and 'srch_destination_id' in train_df.columns and 'prop_country_id' in train_df.columns:\n",
       "    print(\"Investigating if srch_destination_id could be a country ID by comparing with prop_country_id...\")\n",
       "    # Calculate the percentage of times srch_destination_id matches prop_country_id\n",
       "    matches = (train_df['srch_destination_id'] == train_df['prop_country_id']).sum()\n",
       "    total_rows = len(train_df)\n",
       "    percentage_match = (matches / total_rows) * 100 if total_rows > 0 else 0\n",
       "    \n",
       "    print(f\"Number of times srch_destination_id matches prop_country_id: {matches}\")\n",
       "    print(f\"Total rows analyzed: {total_rows}\")\n",
       "    print(f\"Percentage of matches: {percentage_match:.2f}%\")\n",
       "    \n",
       "    # Further analysis: Check unique values and distributions if they don't match often\n",
       "    if percentage_match < 90: # Using a threshold to decide if further investigation is needed\n",
       "        print(\"\\nSince the match percentage is not very high, let's look at the unique values count for each:\\n\")\n",
       "        print(f\"Unique srch_destination_id values: {train_df['srch_destination_id'].nunique()}\")\n",
       "        print(f\"Unique prop_country_id values: {train_df['prop_country_id'].nunique()}\")\n",
       "        \n",
       "        mismatched_df = train_df[train_df['srch_destination_id'] != train_df['prop_country_id']][['srch_destination_id', 'prop_country_id']]\n",
       "        if not mismatched_df.empty:\n",
       "            print(\"\\nSample of rows where srch_destination_id != prop_country_id (first 5):\")\n",
       "            display(mismatched_df.head())\n",
       "            \n",
       "            print(\"\\nValue counts for srch_destination_id in mismatched rows (top 5):\")\n",
       "            display(mismatched_df['srch_destination_id'].value_counts().head())\n",
       "            \n",
       "            print(\"\\nValue counts for prop_country_id in mismatched rows (top 5):\")\n",
       "            display(mismatched_df['prop_country_id'].value_counts().head())\n",
       "        else:\n",
       "            if total_rows > 0: # Only print this if we actually had data to compare\n",
       "                print(\"\\nAll srch_destination_id values match prop_country_id (this is unexpected given the percentage).\")\n",
       "else:\n",
       "    print(\"Skipping srch_destination_id vs prop_country_id analysis: DataFrame is not loaded or required columns are missing.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "fam_brand_md",
      "metadata": {},
      "source": [
       "## 3. Investigate Family Preference for Brand Hotels (`prop_brand_bool`)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "fam_brand_code",
      "metadata": {},
      "outputs": [],
      "source": [
       "if 'train_df' in locals() and not train_df.empty and 'srch_children_count' in train_df.columns and 'prop_brand_bool' in train_df.columns:\n",
       "    print(\"Investigating family preference for brand hotels (prop_brand_bool)...\")\n",
       "\n",
       "    # Create a boolean column for 'is_family_search'\n",
       "    # Ensure srch_children_count is integer, handle NaNs by filling with 0 (no children)\n",
       "    train_df['is_family_search'] = train_df['srch_children_count'].fillna(0).astype(int) > 0\n",
       "\n",
       "    # Calculate the proportion of brand hotels (prop_brand_bool == 1) for family searches vs. non-family searches\n",
       "    # prop_brand_bool: +1 if the hotel is part of a major hotel chain; 0 if it is an independent hotel\n",
       "    brand_preference_by_family_status = train_df.groupby('is_family_search')['prop_brand_bool'].value_counts(normalize=True).mul(100).unstack(fill_value=0)\n",
       "    \n",
       "    print(\"\\nProportion of Listings by Hotel Type (Brand vs. Non-Brand) and Search Type (%):\\n\")\n",
       "    if 1 in brand_preference_by_family_status.columns and 0 in brand_preference_by_family_status.columns:\n",
       "        # Rename columns and index for clarity\n",
       "        display_table = brand_preference_by_family_status.rename(\n",
       "            columns={0: 'Non-Brand Hotel (%)', 1: 'Brand Hotel (%)'},\n",
       "            index={False: 'Search without Children', True: 'Search with Children'}\n",
       "        )\n",
       "        display(display_table)\n",
       "        \n",
       "        # Visualization\n",
       "        if not display_table.empty:\n",
       "            plot_table = display_table[['Brand Hotel (%)', 'Non-Brand Hotel (%)']]\n",
       "            plot_table.plot(kind='bar', figsize=(10, 7), stacked=False)\n",
       "            plt.title('Hotel Type Preference: Searches With vs. Without Children')\n",
       "            plt.ylabel('Percentage of Listings (%)')\n",
       "            plt.xlabel('Search Type')\n",
       "            plt.xticks(rotation=0)\n",
       "            plt.legend(title='Hotel Type')\n",
       "            plt.tight_layout()\n",
       "            plt.show()\n",
       "        else:\n",
       "            print(\"No data to plot.\")\n",
       "\n",
       "    elif 1 in brand_preference_by_family_status.columns: # Only Brand hotels found in one or both groups\n",
       "        display_table = brand_preference_by_family_status.rename(\n",
       "            columns={1: 'Brand Hotel (%)'},\n",
       "            index={False: 'Search without Children', True: 'Search with Children'}\n",
       "        )\n",
       "        if 0 not in display_table.columns:\n",
       "             display_table['Non-Brand Hotel (%)'] = 0\n",
       "        display(display_table[['Brand Hotel (%)', 'Non-Brand Hotel (%)']])\n",
       "        print(\"Note: 'Non-Brand Hotel (%)' might be 0 if no non-brand hotels were found for these groups.\")\n",
       "\n",
       "    elif 0 in brand_preference_by_family_status.columns: # Only Non-Brand hotels found\n",
       "        display_table = brand_preference_by_family_status.rename(\n",
       "            columns={0: 'Non-Brand Hotel (%)'},\n",
       "            index={False: 'Search without Children', True: 'Search with Children'}\n",
       "        )\n",
       "        if 1 not in display_table.columns:\n",
       "            display_table['Brand Hotel (%)'] = 0\n",
       "        display(display_table[['Brand Hotel (%)', 'Non-Brand Hotel (%)']])\n",
       "        print(\"Note: 'Brand Hotel (%)' might be 0 if no brand hotels were found for these groups.\")\n",
       "    else:\n",
       "        print(\"Could not generate detailed brand preference table. Raw counts per group:\")\n",
       "        print(train_df.groupby('is_family_search')['prop_brand_bool'].value_counts().unstack(fill_value=0))\n",
       "\n",
       "    # Clean up the added column if you don't need it for further immediate analysis\n",
       "    # del train_df['is_family_search'] \n",
       "else:\n",
       "    print(\"Skipping family preference analysis: DataFrame is not loaded or 'srch_children_count'/'prop_brand_bool' columns are missing.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "los_bw_md",
      "metadata": {},
      "source": [
       "## 4. Length of Stay vs. Booking Window Analysis"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "los_bw_code",
      "metadata": {},
      "outputs": [],
      "source": [
       "if 'train_df' in locals() and not train_df.empty and 'srch_length_of_stay' in train_df.columns and 'srch_booking_window' in train_df.columns:\n",
       "    print(\"Analyzing relationship between Length of Stay and Booking Window...\")\n",
       "    \n",
       "    # Remove rows with NaN in these specific columns for this analysis\n",
       "    analysis_df = train_df[['srch_length_of_stay', 'srch_booking_window']].dropna()\n",
       "    \n",
       "    # Cap values for better visualization (extreme outliers can skew the plot)\n",
       "    # These caps are arbitrary and can be adjusted based on data distribution\n",
       "    analysis_df['srch_length_of_stay_capped'] = analysis_df['srch_length_of_stay'].clip(upper=30) # Cap length of stay at 30 days\n",
       "    analysis_df['srch_booking_window_capped'] = analysis_df['srch_booking_window'].clip(upper=365) # Cap booking window at 1 year\n",
       "    \n",
       "    # Calculate correlation\n",
       "    correlation = analysis_df['srch_length_of_stay'].corr(analysis_df['srch_booking_window'])\n",
       "    print(f\"\\nCorrelation between Length of Stay and Booking Window: {correlation:.4f}\")\n",
       "    \n",
       "    # Hexbin plot for density visualization\n",
       "    plt.figure(figsize=(12, 8))\n",
       "    hb = plt.hexbin(analysis_df['srch_booking_window_capped'], analysis_df['srch_length_of_stay_capped'], gridsize=50, cmap='YlGnBu', mincnt=1)\n",
       "    plt.colorbar(hb, label='Count in Bin')\n",
       "    plt.xlabel('Booking Window (Days - Capped at 365)')\n",
       "    plt.ylabel('Length of Stay (Nights - Capped at 30)')\n",
       "    plt.title('Density Plot: Length of Stay vs. Booking Window')\n",
       "    plt.show()\n",
       "    \n",
       "    # Scatter plot for a smaller sample for clearer individual points\n",
       "    sample_df = analysis_df.sample(n=min(5000, len(analysis_df)), random_state=42)\n",
       "    plt.figure(figsize=(12, 8))\n",
       "    sns.scatterplot(data=sample_df, x='srch_booking_window_capped', y='srch_length_of_stay_capped', alpha=0.5)\n",
       "    plt.xlabel('Booking Window (Days - Capped at 365)')\n",
       "    plt.ylabel('Length of Stay (Nights - Capped at 30)')\n",
       "    plt.title('Scatter Plot: Length of Stay vs. Booking Window (Sampled & Capped)')\n",
       "    plt.show()\n",
       "else:\n",
       "    print(\"Skipping Length of Stay vs. Booking Window analysis: DataFrame not loaded or required columns missing.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "price_star_md",
      "metadata": {},
      "source": [
       "## 5. Price Sensitivity and Star Rating Analysis"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "price_star_code",
      "metadata": {},
      "outputs": [],
      "source": [
       "if 'train_df' in locals() and not train_df.empty and 'price_usd' in train_df.columns and 'prop_starrating' in train_df.columns:\n",
       "    print(\"Analyzing Price USD by Property Star Rating...\")\n",
       "    \n",
       "    # Filter out extreme price outliers for better visualization in box plot\n",
       "    # Using a quantile range, e.g., 0.01 to 0.99\n",
       "    price_low_quantile = train_df['price_usd'].quantile(0.01)\n",
       "    price_high_quantile = train_df['price_usd'].quantile(0.99)\n",
       "    analysis_df_price_star = train_df[(train_df['price_usd'] >= price_low_quantile) & (train_df['price_usd'] <= price_high_quantile)]\n",
       "    \n",
       "    plt.figure(figsize=(14, 8))\n",
       "    sns.boxplot(data=analysis_df_price_star, x='prop_starrating', y='price_usd', palette='viridis')\n",
       "    plt.xlabel('Property Star Rating')\n",
       "    plt.ylabel('Price USD (Outliers Filtered for Plot)')\n",
       "    plt.title('Distribution of Price USD by Property Star Rating')\n",
       "    plt.ylim(0, analysis_df_price_star['price_usd'].max() * 1.05) # Adjust y-limit slightly above max for clarity\n",
       "    plt.show()\n",
       "    \n",
       "    # Also analyze visitor_hist_adr_usd vs price_usd\n",
       "    if 'visitor_hist_adr_usd' in train_df.columns:\n",
       "        print(\"\\nAnalyzing Visitor Historical ADR vs. Current Search Price USD...\")\n",
       "        hist_price_df = train_df[['visitor_hist_adr_usd', 'price_usd']].dropna()\n",
       "        \n",
       "        # Filter outliers for these as well for plotting\n",
       "        hist_adr_low = hist_price_df['visitor_hist_adr_usd'].quantile(0.01)\n",
       "        hist_adr_high = hist_price_df['visitor_hist_adr_usd'].quantile(0.99)\n",
       "        price_low = hist_price_df['price_usd'].quantile(0.01)\n",
       "        price_high = hist_price_df['price_usd'].quantile(0.99)\n",
       "        \n",
       "        plot_hist_price_df = hist_price_df[\n",
       "            (hist_price_df['visitor_hist_adr_usd'] >= hist_adr_low) & (hist_price_df['visitor_hist_adr_usd'] <= hist_adr_high) &\n",
       "            (hist_price_df['price_usd'] >= price_low) & (hist_price_df['price_usd'] <= price_high)\n",
       "        ]\n",
       "        \n",
       "        correlation_hist_price = plot_hist_price_df['visitor_hist_adr_usd'].corr(plot_hist_price_df['price_usd'])\n",
       "        print(f\"Correlation between Visitor Historical ADR and Current Price USD (filtered): {correlation_hist_price:.4f}\")\n",
       "        \n",
       "        plt.figure(figsize=(12, 8))\n",
       "        # Using hexbin for density as scatter can be too dense\n",
       "        hb_hist = plt.hexbin(plot_hist_price_df['visitor_hist_adr_usd'], plot_hist_price_df['price_usd'], gridsize=40, cmap='Blues', mincnt=1)\n",
       "        plt.colorbar(hb_hist, label='Count in Bin')\n",
       "        plt.xlabel('Visitor Historical ADR (USD - Filtered)')\n",
       "        plt.ylabel('Current Search Price (USD - Filtered)')\n",
       "        plt.title('Density: Visitor Historical ADR vs. Current Search Price')\n",
       "        plt.show()\n",
       "    else:\n",
       "        print(\"\\nSkipping Visitor Historical ADR analysis: 'visitor_hist_adr_usd' column missing.\")\n",
       "else:\n",
       "    print(\"Skipping Price USD vs. Star Rating analysis: DataFrame not loaded or required columns missing.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "promo_impact_md",
      "metadata": {},
      "source": [
       "## 6. Impact of Promotions on Hotel Characteristics"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "promo_impact_code",
      "metadata": {},
      "outputs": [],
      "source": [
       "if 'train_df' in locals() and not train_df.empty and 'promotion_flag' in train_df.columns and 'prop_starrating' in train_df.columns:\n",
       "    print(\"Analyzing Impact of Promotions on Property Star Rating Distribution...\")\n",
       "    \n",
       "    plt.figure(figsize=(12, 7))\n",
       "    sns.countplot(data=train_df, x='prop_starrating', hue='promotion_flag', palette={0: 'skyblue', 1: 'salmon'})\n",
       "    plt.xlabel('Property Star Rating')\n",
       "    plt.ylabel('Number of Listings')\n",
       "    plt.title('Distribution of Property Star Ratings by Promotion Flag')\n",
       "    legend_labels = ['No Promotion', 'Promotion']\n",
       "    plt.legend(title='Promotion Status', labels=legend_labels)\n",
       "    plt.show()\n",
       "    \n",
       "    # Proportion of promoted listings within each star rating\n",
       "    promo_by_star = train_df.groupby('prop_starrating')['promotion_flag'].value_counts(normalize=True).mul(100).unstack(fill_value=0)\n",
       "    if 1 in promo_by_star.columns: # Check if there are any promotions\n",
       "        promo_by_star = promo_by_star.rename(columns={0: 'No Promo (%)', 1: 'Promo (%)'})\n",
       "        print(\"\\nPercentage of Promoted Listings within Each Star Rating Category:\\n\")\n",
       "        display(promo_by_star)\n",
       "        \n",
       "        if 'Promo (%)' in promo_by_star.columns:\n",
       "            promo_by_star['Promo (%)'].plot(kind='bar', figsize=(10,6), color='salmon')\n",
       "            plt.title('Percentage of Promoted Listings by Star Rating')\n",
       "            plt.xlabel('Property Star Rating')\n",
       "            plt.ylabel('Percentage Promoted (%)')\n",
       "            plt.xticks(rotation=0)\n",
       "            plt.show()\n",
       "    else:\n",
       "        print(\"\\nNo promoted listings found in the dataset to analyze by star rating.\")\n",
       "        \n",
       "else:\n",
       "    print(\"Skipping Promotion Impact analysis: DataFrame not loaded or required columns missing.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "target_corr_md",
      "metadata": {},
      "source": [
       "## 7. Correlation with Target Variable (`booking_bool`)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "target_corr_code",
      "metadata": {},
      "outputs": [],
      "source": [
       "if 'train_df' in locals() and not train_df.empty and 'booking_bool' in train_df.columns:\n",
       "    print(\"Calculating correlation of features with booking_bool...\")\n",
       "    \n",
       "    # Select numerical features and boolean-like features that can be treated as numeric\n",
       "    # Exclude direct leakers like 'gross_booking_usd' and 'click_bool'\n",
       "    # Also exclude 'date_time' for direct correlation, and high-cardinality IDs that are not ordinal\n",
       "    potential_features = train_df.select_dtypes(include=[np.number, 'bool']).columns.tolist()\n",
       "    \n",
       "    # Features to exclude from correlation analysis with booking_bool\n",
       "    # 'srch_id' is an identifier, not a feature for this type of correlation.\n",
       "    # 'gross_booking_usd' and 'click_bool' are direct leakers or part of the target definition.\n",
       "    features_to_exclude = ['srch_id', 'gross_booking_usd', 'click_bool']\n",
       "    \n",
       "    # For competitor features, fill NaNs to allow correlation calculation (e.g., with 0 or a specific value if meaningful)\n",
       "    # For simplicity, we'll create a copy and fill NaNs for comp features with 0 for correlation purposes.\n",
       "    df_for_corr = train_df.copy()\n",
       "    comp_cols = [col for col in df_for_corr.columns if 'comp' in col and ('rate' in col or 'inv' in col or 'diff' in col)]\n",
       "    for col in comp_cols:\n",
       "        if df_for_corr[col].isnull().any():\n",
       "            df_for_corr[col] = df_for_corr[col].fillna(0) # Example: fill with 0 (neutral)\n",
       "            \n",
       "    numeric_and_boolean_features = []\n",
       "    for col in df_for_corr.columns:\n",
       "        if col not in features_to_exclude and col != 'booking_bool':\n",
       "            if df_for_corr[col].dtype in [np.number, 'int64', 'float64', 'bool']:\n",
       "                 numeric_and_boolean_features.append(col)\n",
       "            elif pd.api.types.is_numeric_dtype(df_for_corr[col]): # Catch other numeric types like Int64\n",
       "                 numeric_and_boolean_features.append(col)\n",
       "\n",
       "    if not numeric_and_boolean_features:\n",
       "        print(\"No suitable numeric or boolean features found for correlation analysis with booking_bool.\")\n",
       "    else:\n",
       "        # Calculate correlations\n",
       "        correlations = df_for_corr[numeric_and_boolean_features + ['booking_bool']].corr()['booking_bool'].sort_values(ascending=False)\n",
       "        # Remove the booking_bool self-correlation\n",
       "        correlations = correlations.drop('booking_bool', errors='ignore')\n",
       "        \n",
       "        print(\"\\nTop/Bottom Correlations with booking_bool:\\n\")\n",
       "        display(correlations)\n",
       "        \n",
       "        # Visualization\n",
       "        plt.figure(figsize=(10, max(8, len(correlations) * 0.3))) # Adjust height based on number of features\n",
       "        sns.barplot(x=correlations.values, y=correlations.index, palette='coolwarm')\n",
       "        plt.title('Feature Correlation with booking_bool')\n",
       "        plt.xlabel('Correlation Coefficient')\n",
       "        plt.ylabel('Feature')\n",
       "        plt.axvline(x=0, color='grey', lw=1)\n",
       "        plt.tight_layout()\n",
       "        plt.show()\n",
       "else:\n",
       "    print(\"Skipping correlation with booking_bool: DataFrame not loaded or 'booking_bool' column missing.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "recurring_cust_md",
      "metadata": {},
      "source": [
       "## 8. Customer Type Analysis (New vs. Recurring) and Booking Behavior"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "recurring_cust_feature_code",
      "metadata": {},
      "outputs": [],
      "source": [
       "if 'train_df' in locals() and not train_df.empty and 'visitor_hist_starrating' in train_df.columns and 'visitor_hist_adr_usd' in train_df.columns:\n",
       "    print(\"Creating 'is_recurring_customer' feature...\")\n",
       "    \n",
       "    # A customer is considered recurring if they have a historical star rating OR historical average daily rate.\n",
       "    condition = train_df['visitor_hist_starrating'].notna() | train_df['visitor_hist_adr_usd'].notna()\n",
       "    train_df['is_recurring_customer'] = condition.astype(int)\n",
       "    \n",
       "    print(\"Value counts for 'is_recurring_customer':\")\n",
       "    display(train_df['is_recurring_customer'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%')\n",
       "    display(train_df['is_recurring_customer'].value_counts())\n",
       "else:\n",
       "    print(\"Skipping 'is_recurring_customer' feature creation: DataFrame not loaded or required history columns missing.\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "recurring_cust_analysis_code",
      "metadata": {},
      "outputs": [],
      "source": [
       "if 'train_df' in locals() and not train_df.empty and 'is_recurring_customer' in train_df.columns and 'booking_bool' in train_df.columns:\n",
       "    print(\"\\nAnalyzing booking behavior by customer type (New vs. Recurring)...\")\n",
       "    \n",
       "    # Calculate booking rate for each customer type\n",
       "    booking_rate_by_customer_type = train_df.groupby('is_recurring_customer')['booking_bool'].mean().mul(100).reset_index()\n",
       "    booking_rate_by_customer_type['is_recurring_customer'] = booking_rate_by_customer_type['is_recurring_customer'].map({0: 'New Customer', 1: 'Recurring Customer'})\n",
       "    booking_rate_by_customer_type = booking_rate_by_customer_type.rename(columns={'booking_bool': 'Booking Rate (%)'})\n",
       "    \n",
       "    print(\"\\nBooking Rate by Customer Type:\\n\")\n",
       "    display(booking_rate_by_customer_type)\n",
       "    \n",
       "    # Visualization\n",
       "    plt.figure(figsize=(8, 6))\n",
       "    sns.barplot(data=booking_rate_by_customer_type, x='is_recurring_customer', y='Booking Rate (%)', palette={'New Customer': 'skyblue', 'Recurring Customer': 'salmon'})\n",
       "    plt.title('Booking Rate: New vs. Recurring Customers')\n",
       "    plt.ylabel('Booking Rate (%)')\n",
       "    plt.xlabel('Customer Type')\n",
       "    plt.ylim(0, max(booking_rate_by_customer_type['Booking Rate (%)']) * 1.2 if not booking_rate_by_customer_type.empty else 10) # Dynamic y-limit\n",
       "    plt.tight_layout()\n",
       "    plt.show()\n",
       "    \n",
       "    # Chi-squared test for independence (optional, for statistical significance)\n",
       "    from scipy.stats import chi2_contingency\n",
       "    contingency_table = pd.crosstab(train_df['is_recurring_customer'], train_df['booking_bool'])\n",
       "    print(\"\\nContingency Table for Chi-squared Test:\")\n",
       "    display(contingency_table)\n",
       "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
       "    print(f\"Chi-squared statistic: {chi2:.4f}\")\n",
       "    print(f\"P-value: {p:.4f}\")\n",
       "    if p < 0.05:\n",
       "        print(\"The p-value is less than 0.05, suggesting a statistically significant association between customer type and booking behavior.\")\n",
       "    else:\n",
       "        print(\"The p-value is not less than 0.05, suggesting no statistically significant association (or insufficient evidence). \")\n",
       "\n",
       "else:\n",
       "    print(\"\\nSkipping analysis of booking behavior by customer type: 'is_recurring_customer' or 'booking_bool' column missing, or DataFrame not loaded.\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "41c509b1-28c2-4639-8764-5f60b1fa57e8",
      "metadata": {},
      "outputs": [],
      "source": []
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }